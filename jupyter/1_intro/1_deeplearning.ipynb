{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ce3e92-e1a1-4162-a747-d17b76bd3888",
   "metadata": {},
   "source": [
    "# L1 Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a59818b-cc11-41da-a38a-ef179f45e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9160b388-71ff-40ae-8f4a-9fd04278d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4974a-c234-4776-8d0e-d438236e829f",
   "metadata": {},
   "source": [
    "## Prompt the model and get a completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f2d20d-5e71-4694-83ff-8dc506427eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3706ca-2782-41db-b1ed-2edc5a65d752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50eac25a-83a6-407f-b1e2-2a3f39eef1c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87fc525a-d881-4407-9e7e-10039976a188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Take the letters in l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fc97e1-645d-4a76-9f44-544386bdf4de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4dc834e-4aee-4624-9a78-fd96fbf68d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(\n",
    "    messages, \n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    temperature=0, \n",
    "    max_tokens=500\n",
    "):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83550630-1e83-4a9e-81fe-5c0d0547dfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, happy carrot, orange and bright,\n",
      "Growing tall with utmost delight.\n",
      "In the garden, you sparkle and gleam,\n",
      "Living your vegetable dream.\n",
      "\n",
      "With a crunchy crunch and a crispy snap,\n",
      "You make us smile with a healthy snack.\n",
      "Filled with vitamins, you're oh so nourishing,\n",
      "A wholesome treat, truly flourishing.\n",
      "\n",
      "Oh, happy carrot, you bring us joy,\n",
      "Whether eaten raw or in a stir-fry.\n",
      "Your vibrant color, so full of cheer,\n",
      "A humble veggie we hold dear.\n",
      "\n",
      "So let us celebrate this joyful crop,\n",
      "With every bite, we never stop.\n",
      "Thank you, happy carrot, for all you do,\n",
      "Bringing smiles and health to me and you!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "    {\n",
    "     'role':'system', \n",
    "     'content':\"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\"\n",
    "    },    \n",
    "    {\n",
    "     'role':'user', \n",
    "     'content':\"\"\"write me a very short poem about a happy carrot\"\"\"\n",
    "    },  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb8d8c6-f9e3-4cb9-86db-29303958dc0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Carl who grew up in a vibrant garden.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':'All your responses must be one sentence long.'},    \n",
    "    {\n",
    "        'role':'user',\n",
    "        'content':'write me a story about a happy carrot'\n",
    "    },  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073f1fae-a927-4a00-9ef4-8988f32570e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a garden so grand, grew a happy carrot named Andy, with a smile so big and grand.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "    {\n",
    "        'role':'system',\n",
    "        'content':\"\"\"You are an assistant who responds in the style of Dr Seuss. All your responses must be one sentence long.\"\"\"\n",
    "    },    \n",
    "    {\n",
    "        'role':'user',\n",
    "        'content':\"\"\"write me a story about a happy carrot\"\"\"\n",
    "    },\n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f07b53-be88-4a26-85fc-f64fb5d3504c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(\n",
    "    messages, \n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    temperature=0, \n",
    "    max_tokens=500\n",
    "):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "        'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "        'completion_tokens':response['usage']['completion_tokens'],\n",
    "        'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e10f1aec-324d-4205-9866-45b0a18d09a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role':'system', \n",
    "         'content':\"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\"\n",
    "    },    \n",
    "    {\n",
    "        'role':'user',\n",
    "        'content':\"\"\"write me a very short poem about a happy carrot\"\"\"\n",
    "    },  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "692f4937-aeb0-4e5f-82cc-24be0087f96f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Grown in the garden, a joyful forage.\n",
      "With a smile so wide, from top to bottom,\n",
      "It fills our hearts with pure veggie autumn.\n",
      "\n",
      "In the soil it dances, with roots so deep,\n",
      "Growing tall and strong, a promise to keep.\n",
      "With every bite, a crunch so sweet,\n",
      "The happy carrot, a tasty treat.\n",
      "\n",
      "From garden to table, it brings delight,\n",
      "A burst of flavor, oh what a sight!\n",
      "So let's celebrate this veggie star,\n",
      "The happy carrot, no matter how far.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30dcefb-c54b-4190-8a69-1bb86ace591c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 35, 'completion_tokens': 118, 'total_tokens': 153}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d9969-1565-438b-b8e6-2169c57578d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
